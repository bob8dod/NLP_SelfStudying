{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "어텐션 메커니즘(Attention mechanism).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPx3cwSzFk8Sc0PstC96LsX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bob8dod/NLP_SelfStudying/blob/main/Attention_mechanism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBOvotjh7ZQL"
      },
      "source": [
        "## 양방향 LSTM과 어텐션 메커니즘(BiLSTM with Attention mechanism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLls0G1i7gUp"
      },
      "source": [
        "### IMDB 리뷰 데이터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osE8ooUF7RAH"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4gZTK-a7jIb",
        "outputId": "84c05c67-88d1-4542-b231-a754c03d165f"
      },
      "source": [
        "vocab_size = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfxYWZEK8Lbd",
        "outputId": "724695b0-4db1-4aa2-b5f0-c01d30228305"
      },
      "source": [
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2GujQ4z8PPs"
      },
      "source": [
        "max_len = 500 #평균길이보다 약 2배 길게 패딩 진행\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsbzi0yH8dWT"
      },
      "source": [
        "### 바다나우 어텐션(Bahdanau Attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbH4NPpw9HKi"
      },
      "source": [
        "바다나우 어텐션은 아래와 같은 어텐션 스코어 함수를 사용  \n",
        "이 어텐션 스코어 함수를 사용하여 어텐션 메커니즘을 구현하면 됨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LbalJeV85Gi"
      },
      "source": [
        "![image.png](data:image/png;base64,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)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY2bCQcq9Uaq"
      },
      "source": [
        "이 어텐션 메커니즘을 사용하는 이유?  \n",
        "RNN의 마지막 은닉 상태는 예측을 위해 사용됨. 그런데 이 RNN의 마지막 은닉 상태는 몇 가지 유용한 정보들을 손실한 상태입니다. 그래서 RNN이 time step을 지나며 손실했던 정보들을 다시 참고  \n",
        "=>  RNN의 모든 은닉 상태들을 다시 한 번 참고하겠다는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcRofJb384fm"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV6HmTuj8U4L"
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # query shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # self.V 에 score을 적용할것이기 때문에 1차원 덧붙임\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUxo3e1Q_P-3"
      },
      "source": [
        "### 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEQc6IE2-bRf"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDxgh0Rh_Ukp"
      },
      "source": [
        "# 입력층과 임베딩층 설계\n",
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)\n",
        "\n",
        "# 양방향 LSTM 첫번째 층\n",
        "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)\n",
        "# 두번째 층을 위에 쌓을 예정이므로 return_sequences를 True\n",
        "# 양방향 LSTM 두번째 층\n",
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
        "# 상태를 리턴받아야 하므로 return_state를 True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y13pDyB6_YTh",
        "outputId": "574316b6-807d-4090-c617-86c57b8d6ae5"
      },
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkf2q9BPAWRU"
      },
      "source": [
        "각 은닉 상태나 셀 상태의 경우에는 64차원을 가지는데, lstm의 경우에는 (500 × 128)의 크기를 가짐  \n",
        "=>foward 방향과 backward 방향이 연결된 hidden state벡터가 모든 시점에 대해서 존재함을 의미"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz_gxi8-BSfC"
      },
      "source": [
        "양방향 LSTM의 은닉 상태와 셀 상태를 사용하려면 두 방향의 LSTM의 상태들을 연결(concatenate)해주면 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAKilCqkAM-R"
      },
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj5iR3rfBR8L"
      },
      "source": [
        "# 은닉 상태를 사용하여 이를 입력으로 컨텍스트 벡터(context vector)를 얻기\n",
        "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtlIEFSBCR9C"
      },
      "source": [
        "컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, 이진 분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLAU44jVBjib"
      },
      "source": [
        "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
        "dropout = Dropout(0.5)(dense1)\n",
        "output = Dense(1, activation=\"sigmoid\")(dropout)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgkirrXNCPxk",
        "outputId": "29a33306-43e9-4f0b-a200-23d8ad4ce5c4"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "38/98 [==========>...................] - ETA: 6:13 - loss: 0.6535 - accuracy: 0.6219"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1nK9YkLC3UP"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAHE9zBkC56h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}